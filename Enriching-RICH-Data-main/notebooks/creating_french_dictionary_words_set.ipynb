{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db17fd65-fe7f-4c9b-8399-e9b64bc84159",
   "metadata": {},
   "source": [
    "# Creating a list of French Words\n",
    "\n",
    "\n",
    "## Summary\n",
    "To determine which set of words in the profession string are already having correct spelling and does not require any cleaning a set of correct words is used. Three external data sources are used to create this set of words. The set of words is created in the `cleaning_and_creating_tags.ipynb` notebook. However, in the `creating_french_dictionary_words_set.ipynb` notebook, two of the three external sources are preprocessed and stored as a JSON as pre-processing these files is time-consuming. The notebook reads the two sources of data and stores the words in a JSON file where the keys are the root forms of the words (lemma) and the values are a list of derived words from each lemma (flexions).\n",
    "\n",
    "For a lexicon of the French language, a set of words is provided by ortolang as [Morphalou3](https://repository.ortolang.fr/api/content/morphalou/2/LISEZ_MOI.html#idp37913792) that has 159,271 lemmas and 954,690 inflected forms of modern French is used. \n",
    "\n",
    "For proper nouns, the proper nouns dictionary is sourced from [prolex-unitex](https://tln.lifat.univ-tours.fr/version-francaise/ressources/prolex-unitex). \n",
    "\n",
    "In this notebook, the following files are read\n",
    "- the CSV file provided by Morphalou3 in [Morphalou3_formatCSV_toutEnUn](https://repository.ortolang.fr/api/content/morphalou/2/), whose format is described [here](https://repository.ortolang.fr/api/content/morphalou/2/LISEZ_MOI.html#idp37944688) and\n",
    "- the [DIC file](https://tln.lifat.univ-tours.fr/medias/fichier/prolex-unitex-1-2_1562935068094-zip?ID_FICHE=321994&INLINE=FALSE) provided by Prolex-Unitex in which each row has the word and its details in a single word (such as the context it is used and whether is masculine/feminine and singular or plural) separated by a comma.\n",
    "\n",
    "The CSV and DIC files are read and processed to create a JSON file in the format mentioned above.\n",
    "\n",
    "The data from `Morphalou3` look as shown below and \n",
    "\n",
    "![Morphalou3_CSV_file_format.png](./images/Morphalou3_CSV_file_format.png)\n",
    "\n",
    "and is saved as following into JSON\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"aalénien\": [\n",
    "        \"aalénien\",\n",
    "        \"aaléniens\",\n",
    "        \"aalénienne\",\n",
    "        \"aaléniennes\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "The data from `Prolex-Unitex` looks as following\n",
    "\n",
    "![prolex_unitex_file_format.png](./images/prolex_unitex_file_format.png)\n",
    "\n",
    "and is saved as following into json\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"william pitt, comte de chatham\": [\n",
    "        \"comte de chatham\",\n",
    "        \"william pitt\",\n",
    "        \"william pitt, comte de chatham\"\n",
    "    ],\n",
    "    \"william pitt\": [\n",
    "        \"william pitt\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "The combined JSON of both the files is stored in a single JSON file as \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"aalénien\": [\n",
    "        \"aalénien\",\n",
    "        \"aaléniens\",\n",
    "        \"aalénienne\",\n",
    "        \"aaléniennes\"\n",
    "    ], \n",
    "    \"william pitt, comte de chatham\": [\n",
    "        \"comte de chatham\",\n",
    "        \"william pitt\",\n",
    "        \"william pitt, comte de chatham\"\n",
    "    ],\n",
    "    \"william pitt\": [\n",
    "        \"william pitt\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "## Imports\n",
    "\n",
    "Pandas library is used to read the CSV file, JSON library is used to save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627a13cc-97ec-442d-a607-da4a059c11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a72e5-35f1-44ae-9301-3b1f7f7a844f",
   "metadata": {},
   "source": [
    "### Reading the Morphalou3\n",
    "\n",
    "As there are many columns in the CSV file, only the two required columns of the root word and derived word are read. Although the capitalization attributes certain meaning to the words, due to the design of the pipeline to lower case the words, the words from the dictionaries are also lowercased. The lemme is only mentioned once in the file at its first occurrence and for the rest of the rows only the flexion is mentioned.\n",
    "\n",
    "The first 15 rows in the `Morphalou3_CSV.csv` contain metadata information about the file and hence they are skipped while reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453fb0ca-eb7f-44a6-b204-0cd8f7b82c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [0, 9]\n",
    "\n",
    "header_list = [\"lemme\", \"flexion\"]\n",
    "\n",
    "morphalou_words_df = pd.read_csv(\"./../data/external_data/Morphalou3_formatCSV_toutEnUn/Morphalou3_CSV.csv\",\n",
    "                              skiprows=15, sep=\";\",dtype = 'str', usecols = columns,\n",
    "                              header=0, encoding=\"utf-8\", keep_default_na=False, na_values=\"\", names=header_list)\n",
    "\n",
    "morphalou_words_df[\"lemme\"] = morphalou_words_df[\"lemme\"].str.lower()\n",
    "morphalou_words_df[\"flexion\"] = morphalou_words_df[\"flexion\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f206c341-6f5f-4612-84ea-74cd26539ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e5ad88e18244a792321d6cad572517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty dictionary to store words\n",
    "french_dictionary_category = {}\n",
    "\n",
    "for lemme,flexion in tqdm_notebook(morphalou_words_df.itertuples(index=False)):\n",
    "    # for each lemma and flexion pair\n",
    "    if isinstance(flexion, str):\n",
    "        # if flexion is not NaN\n",
    "        if isinstance(lemme, str):\n",
    "            # if lemme is not NaN, that means there is a new root word\n",
    "            prev_lemme = lemme\n",
    "            if prev_lemme not in french_dictionary_category:\n",
    "                # create its entry in the python dictionary to store the dervied words under it\n",
    "                french_dictionary_category[prev_lemme] = []\n",
    "            \n",
    "        if flexion not in french_dictionary_category[prev_lemme]:\n",
    "            # add the flexion under the lemma\n",
    "            french_dictionary_category[prev_lemme].append(flexion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c857a3e-a3ad-408e-94d2-71bdc755af00",
   "metadata": {},
   "source": [
    "### Reading the Prolex-Unitex\n",
    "\n",
    "There are no standard libraries in python to read the `dic` files. Here, each line of the `dic` file is read and processed. Unlike the `Morphalou3`, the lemma and flexion are not meaningful in proper nouns and most of the time they are the same. In order to facilitate the uniformity to store the data, the following steps are performed.\n",
    "\n",
    "1. For each line get the text component of the line and ignore the additional information (such as its gender or singular or plural) by splitting the text at the last period(`.`).\n",
    "2. Replace the escaped comma (`\\,`) in the text to \\$ temporarily (as the flexion is separated with the lemme by a comma).\n",
    "3. Replace the escaped period (`\\.`) in the text with a normal period.\n",
    "4. Split the text component at the comma. If there is lemme then the second element in the list is the lemme. Otherwise, the lemme and flexion are the same.\n",
    "5. Replace back the \\$ to a comma.\n",
    "6. Add the lemme and the flexion to the python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392a8c55-b3a1-4a6e-8d2d-9aeb19add59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_nouns_file = open(\"./../data/external_data/Prolex-Unitex_1_2/Prolex-Unitex_1_2.dic\", encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79dd63a9-2cdf-4904-b726-46d72125924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f457d558384fa99d462c3fea9dd81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dict_line in tqdm_notebook(proper_nouns_file):\n",
    "    # get the text component of the line and ignore the additional information by splitting the text at the last period.\n",
    "    # replace the escaped comma in the text to $ temporarily (as the flexion is seperated with the lemme by a comma).\n",
    "    # replace the escaped period in the text to normal period.\n",
    "    # Then split the text component at the comma. If there is lemme then the second element in the list is the lemme. Otherwise\n",
    "    # it is empty.\n",
    "    text_component = dict_line.lower().rsplit(\".\", 1)[0].replace(\"\\.\", \".\").replace(\"\\,\", \"$\").split(\",\")\n",
    "            \n",
    "    flexion, lemme = text_component\n",
    "    flexion, lemme = flexion.replace(\"$\", \",\"), lemme.replace(\"$\", \",\")\n",
    "        \n",
    "    if not lemme:\n",
    "        lemme = flexion\n",
    "        \n",
    "    if lemme not in french_dictionary_category:\n",
    "        french_dictionary_category[lemme] = []\n",
    "\n",
    "    if flexion not in french_dictionary_category[lemme]:\n",
    "        french_dictionary_category[lemme].append(flexion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eaea89-3356-4908-bcf3-c6bbb16b07af",
   "metadata": {},
   "source": [
    "### Saving\n",
    "\n",
    "The Python dictionary is saved as JSON to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23abc56-36d3-4c78-8800-a7021cc7900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../data/intermediate_steps/words_from_french_language_dictionaries.json\", \"w\", encoding ='utf8') as outfile:\n",
    "    json.dump(french_dictionary_category, outfile, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98706f71-4ce3-4914-b0be-3a8612940310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "098a0dd3104dda9245e32bc4140980e8acec008f0fd7b1a1afbd38055ea17b26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
