{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment\n",
    "## Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from alignment import align_on_column, get_fuzzy_dict\n",
    "from preprocessing import substitute_col_by_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variable to True if you want to use dataset with profession tags (preprocessed with parts of Ravis Code)\n",
    "USE_TAGGED_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TAGGED_DATASET:\n",
    "    bottins = pd.read_pickle(\"data/bottins_tagged_prep.pkl\")\n",
    "else:\n",
    "    bottins = pd.read_pickle(\"data/bottins_prep.pkl\")\n",
    "    \n",
    "streets = pd.read_pickle(\"data/FinalUnique.pkl\")\n",
    "unique_short_s = pd.read_pickle(\"data/unique_short_streets.pkl\")\n",
    "non_unique_short_s = pd.read_pickle(\"data/not_unique_short_streets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottins.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned, not_aligned = align_on_column(df_not_aligned = bottins, df_streets = streets, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"streetname_prep\", align_method=\"perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", align_method=\"perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", align_method=\"perfect short\")                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitute words by dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {\"boulevard\": \"boulevard de\",\n",
    "                \"boulevard de de \": \"boulevard de \",\n",
    "                \"boulevard de d'\": \"boulevard d'\",\n",
    "                \"boulevards\": \"boulevard des\",\n",
    "                \"damede\": \"dame de\",\n",
    "                \"damedes\": \"dame des\",\n",
    "                \"faubourgsaint\": \"faubourg saint\",\n",
    "                \"faubourgpoissonniere\": \"faubourg poissonniere\",\n",
    "                \"faubourgdu\": \"faubourg du\",\n",
    "                \"faubourgmontmartre\": \"faubourg montmartre\",\n",
    "                \"quai jemmapes\": \"quai de jemmapes\",\n",
    "                \"boulevards italiens\": \"boulevard des italiens\",\n",
    "                \"villeneuve\": \"ville neuve\",\n",
    "                \"quai valmy\": \"quai de valmy\",\n",
    "                \"avenue wagram\": \"avenue de wagram\",\n",
    "                \"boulevard de montparnasse\": \"boulevard du montparnasse\"\n",
    "                }\n",
    "\n",
    "# substitute abbreviations\n",
    "not_aligned[\"rue_processed\"] = substitute_col_by_dict(not_aligned[\"rue_processed\"], word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    df_aligned= u_short_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", \n",
    "                    align_method=\"perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    df_aligned= nu_short_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", \n",
    "                    align_method=\"perfect short\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = Counter(not_aligned[\"rue_processed\"]).most_common(100)\n",
    "for t in most_common:\n",
    "    rue, occur = t\n",
    "    last = rue.split()[-1]\n",
    "    print(rue, occur, [x for x in streets[\"streetname_prep\"] if last in x], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if something exists in the streets dataset\n",
    "print([x for x in streets[\"streetname_prep\"] if \"boulevards\" in x])\n",
    "#print(streets[streets[\"name_prep\"]==\"la fayette\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common in not aligned data\n",
    "Counter([x for x in not_aligned[\"rue_processed\"] if \".\" in x]).most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment without spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_spaces = {\"\\ \":\"\", \"\\|\":\"\", \"\\.\":\"\", \"\\:\":\"\", \"\\'\":\"\"}\n",
    "not_aligned[\"no_spaces\"] = not_aligned[\"rue_processed\"].replace(replace_spaces, regex=True)\n",
    "streets[\"no_spaces_long\"] = streets[\"streetname_prep\"].replace(replace_spaces, regex=True)\n",
    "unique_short_s[\"no_spaces_short\"] = unique_short_s[\"name_prep\"].replace(replace_spaces, regex=True)\n",
    "non_unique_short_s[\"no_spaces_short\"] = non_unique_short_s[\"name_prep\"].replace(replace_spaces, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_aligned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_long\", \n",
    "                    align_method=\"no spaces perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    df_aligned = u_short_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_short\",\n",
    "                    align_method=\"no spaces perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    df_aligned = nu_short_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_short\",\n",
    "                    align_method=\"no spaces perfect short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_short_aligned.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligned data so far:\", (len(long_aligned)+len(u_short_aligned)+len(nu_short_aligned))/len(bottins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned[[\"nom\", \"metier\", \"rue\", \"numero\", \"year\", \"streetname\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned[[\"nom\", \"metier\", \"rue\", \"numero\", \"year\", \"streetname\", \"no_spaces\"]].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_unique_short_s[[\"name_prep\", \"streetname\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in not_aligned[\"rue\"] if (\"5\" in x)][10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "def simple_processor(token: str) -> str:\n",
    "    \"\"\"A string processor to return the same string as input.\n",
    "        This dummy processor is used to avoid the default processor of the Rapidfuzz module to calculate string similarity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token : str\n",
    "        The input string to process.\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The output string same as the input string.\n",
    "    \"\"\"\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a subset of all non-aligned rows, because otherwise computation is too heavy\n",
    "not_aligned_rues = not_aligned[\"rue_processed\"].unique().tolist()\n",
    "not_aligned_selected = [street for street, _ in Counter(not_aligned[\"rue_processed\"].tolist()).most_common(10000)]\n",
    "#first 100 streets for first analysis\n",
    "not_aligned_selected100 = not_aligned_rues[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_all_vars = streets[\"streetname_prep\"]\n",
    "#streets_all_vars.append(streets[\"streetname_short\"])\n",
    "#streets_all_vars.append(streets[\"streetname_short_prep\"])\n",
    "streets_all_vars = list(set(streets_all_vars))\n",
    "streets_all_vars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying a fuzzy matching for similarity value 85%\n",
    "for x in not_aligned_selected100:\n",
    "    best_one = process.extractOne(x, streets_all_vars, processor=simple_processor, scorer=fuzz.ratio,\n",
    "    score_cutoff=85)\n",
    "    #if there is a matching street with similarity > 85 %, print it\n",
    "    if best_one:\n",
    "        print(x, best_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying matching with similarity value of 80%\n",
    "for x in not_aligned_selected100:\n",
    "    best_one = process.extractOne(x, streets_all_vars, processor=simple_processor, scorer=fuzz.ratio,\n",
    "    score_cutoff=80)\n",
    "    # look at those matches between 80 and 90%\n",
    "    if best_one:\n",
    "        if best_one[1]<90:\n",
    "            print(x, best_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fuzzy_dict(streets_all_vars, not_aligned_selected100, score_cutoff=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make two seperate dictionaries, one with score cutoff value 85 and one with 80\n",
    "\n",
    "# if dictionary with cutoff 85 is already there, load it. If not, compute it\n",
    "try:\n",
    "    with open('data/fuzzy_dict10000with85.pkl', 'rb') as f:\n",
    "        fuzzy_dict85 = pickle.load(f)\n",
    "except:\n",
    "    fuzzy_dict85 = get_fuzzy_dict(streets_all_vars, not_aligned_selected, score_cutoff=85)\n",
    "    with open(\"data/fuzzy_dict10000with85.pkl\",\"wb\") as f:\n",
    "        pickle.dump(fuzzy_dict85,f)\n",
    "\n",
    "# same for dictionary with cutoff 80\n",
    "try:\n",
    "    with open('data/fuzzy_dict10000with80.pkl', 'rb') as f:\n",
    "        fuzzy_dict80 = pickle.load(f)\n",
    "except:\n",
    "    fuzzy_dict80 = get_fuzzy_dict(streets_all_vars, not_aligned_selected, score_cutoff=80)\n",
    "    with open(\"data/fuzzy_dict10000with80.pkl\",\"wb\") as f:\n",
    "        pickle.dump(fuzzy_dict80,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# entries for cutoff 80:\", len(fuzzy_dict80), \"cutoff 85:\", len(fuzzy_dict85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in fuzzy_dict85.items():\n",
    "    if \".\" in item[0]:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in not_aligned dataset and map the fuzzy matched streetnames to the entries\n",
    "not_aligned[\"street_fuzzy80\"] = not_aligned[\"rue_processed\"].map(fuzzy_dict80)\n",
    "not_aligned[\"street_fuzzy85\"] = not_aligned[\"rue_processed\"].map(fuzzy_dict85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align on the newly created columns\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"street_fuzzy85\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"fuzzy 85\")\n",
    "\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"street_fuzzy80\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"fuzzy 80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligned data:\", (len(long_aligned)+len(u_short_aligned)+len(nu_short_aligned))/len(bottins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aligned = pd.concat([long_aligned, u_short_aligned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TAGGED_DATASET:\n",
    "        unique_aligned_selection = unique_aligned[[\"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\", \"tags\"]]\n",
    "        unique_aligned_selection.to_pickle(\"data/unique_aligned_tagged.pkl\")\n",
    "else:\n",
    "        unique_aligned_selection = unique_aligned[[\"page\", \"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\"]]\n",
    "        unique_aligned_selection.to_pickle(\"data/unique_aligned.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Assessment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aligned = pd.concat([long_aligned, u_short_aligned, nu_short_aligned])\n",
    "all_aligned = all_aligned[[\"page\", \"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\"]]\n",
    "all_streets = pd.concat([streets, unique_short_s, non_unique_short_s])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview over alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"perfect\", \"perfect short\", \"no spaces perfect\", \"no spaces perfect short\", \"fuzzy 85\", \"fuzzy 80\"]\n",
    "dev_aligned = {}\n",
    "for method in methods:\n",
    "    dev_aligned[method] = len(all_aligned[all_aligned[\"align_method\"]==method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(dev_aligned.keys(), dev_aligned.values())\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Number of alignment entries per method\\n(alignment in order from left to right)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(df, align_methods, sample_size, random_state=42):\n",
    "    df = df[df[\"align_method\"].isin(align_methods)].sample(n=sample_size, random_state=random_state)\n",
    "    data = zip(df[\"rue\"], df[\"streetname\"], df[\"align_method\"])\n",
    "    for i, entry in enumerate(data):\n",
    "        print(f\"{i+1}. bottin: {entry[0]}  -  matched: {entry[1]}   ({entry[2]})\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect Alignment\n",
    "Checking the code below, the alignment is correct in **100%** of the cases.\n",
    "\n",
    "However, the alignment on the short streetnames is by nature sometimes ambiguous, because the short name was used in the Bottin Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"perfect\", \"perfect short\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment without spaces\n",
    "The alignment of the samples below is correct in **100%** of the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"no spaces perfect\", \"no spaces perfect short\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy alignment\n",
    "#### Alignment with threshold 85 (85% of the two strings matched)\n",
    "\n",
    "Correct: **80%**\n",
    "\n",
    "Unclear if correct: **5%**\n",
    "- 6 (two possibilities), \n",
    "- 11 (\"avenue\" matched with \"rue\" -> no avenue in data),\n",
    "- 15 (\"royale\" matched with \"rue\" -> no royale in data),\n",
    "- 21 (\"cité\" matched with \"route\" -> no cité in data),\n",
    "- 26 (\"route\" matched with \"rue\" -> no route in data)\n",
    "\n",
    "Incorrect matches: **15%**\n",
    "- 3, 14, 22, 23, 24, 25, 30, 42, 47, 60, 65, 70, 78, 80, 82\n",
    "\n",
    "(most of incorrect matches because there was not the correct streettype (e.g. \"avenue\" instead of \"rue\") and thus matched to different street entirely)\n",
    "\n",
    "\n",
    "\n",
    "idea for improvement: write custom ratio which punishes non-alignments in last part of string more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"fuzzy 85\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alignment of threshold between 80 and 85\n",
    "\n",
    "correct: **46%**\n",
    "\n",
    "incorrect: **39%**\n",
    "- 2, 6, 8, 11, 12, 14, 17, 18, 24, 25, 26, 29, 31, 34, 38, 39, 42, 43, 44, 46, 51, 56, 59, 62, 66, 67, 69, 70, 78, 85, 86, 87, 88, 92, 95, 96, 97, 98, 100\n",
    "- from this incorrect street type: **7%** (26, 29, 34, 42, 78, 87, 100)\n",
    "\n",
    "unclear: **15%**\n",
    "- 3 (\"rue\" instead of \"chaussée\")\n",
    "- 4 (\"rue\" instead of \"plâtre\")\n",
    "- 10 (\"rue\" instead of \"grenelle\")\n",
    "- 37 (\"cite\" instead of \"rue\")\n",
    "- 40 (\"rue\" instead of \"cloître\")\n",
    "- 41 (\"rue alphonse karr\" instead of \"rue alphonse\")\n",
    "- 48 (\"rue\" instead of \"boulevard\")\n",
    "- 53 (\"rue\" instead of \"rotonde\")\n",
    "- 54 (\"rue\" instead of \"place\")\n",
    "- 57 (\"rue\" instead of \"cloître\")\n",
    "- 73 (\"rue\" instead of \"grénelle\")\n",
    "- 77 (\"rue alphonse karr\" instead of \"rue alphonse\")\n",
    "- 91 (\"rue\" instead of \"impasse\")\n",
    "- 93 (\"rue\" instead of \"cité\")\n",
    "- 99 (\"rue\" instead of \"cité\")\n",
    "\n",
    "-> many wrongly matched because \"correct\" street was not in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for names in street dataset\n",
    "#print([x for x in streets[\"streetname_prep\"] if \"honore\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"fuzzy 80\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Aligned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(not_aligned[\"rue\"]).most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "098a0dd3104dda9245e32bc4140980e8acec008f0fd7b1a1afbd38055ea17b26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
