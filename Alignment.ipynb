{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment\n",
    "\n",
    "The goal of this Notebook is to\n",
    "* align the bottin data with the street network data with the following methods:\n",
    "    1. perfect matching\n",
    "    2. perfect matching without spaces\n",
    "    3. fuzzy matching\n",
    "* assess the quality of the alignment\n",
    "\n",
    "## Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "from alignment import align_on_column, get_fuzzy_dict, simple_processor, print_sample\n",
    "from preprocessing import substitute_col_by_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variable to True if you want to use dataset with profession tags (preprocessed with parts of Ravis Code)\n",
    "USE_TAGGED_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TAGGED_DATASET:\n",
    "    bottins = pd.read_pickle(\"data/bottins_tagged_prep.pkl\")\n",
    "else:\n",
    "    bottins = pd.read_pickle(\"data/bottins_prep.pkl\")\n",
    "    \n",
    "streets = pd.read_pickle(\"data/FinalUnique.pkl\")\n",
    "unique_short_s = pd.read_pickle(\"data/unique_short_streets.pkl\")\n",
    "non_unique_short_s = pd.read_pickle(\"data/not_unique_short_streets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottins.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Align data: Perfect matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect alignment\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = bottins, df_streets = streets, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"streetname_prep\", align_method=\"perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", align_method=\"perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", align_method=\"perfect short\")                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some alignment by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute frequent OCR errors etc. by hand\n",
    "word_dict = {\"boulevard\": \"boulevard de\",\n",
    "                \"boulevard de de \": \"boulevard de \",\n",
    "                \"boulevard de d'\": \"boulevard d'\",\n",
    "                \"boulevards\": \"boulevard des\",\n",
    "                \"damede\": \"dame de\",\n",
    "                \"damedes\": \"dame des\",\n",
    "                \"faubourgsaint\": \"faubourg saint\",\n",
    "                \"faubourgpoissonniere\": \"faubourg poissonniere\",\n",
    "                \"faubourgdu\": \"faubourg du\",\n",
    "                \"faubourgmontmartre\": \"faubourg montmartre\",\n",
    "                \"quai jemmapes\": \"quai de jemmapes\",\n",
    "                \"boulevards italiens\": \"boulevard des italiens\",\n",
    "                \"villeneuve\": \"ville neuve\",\n",
    "                \"quai valmy\": \"quai de valmy\",\n",
    "                \"avenue wagram\": \"avenue de wagram\",\n",
    "                \"boulevard de montparnasse\": \"boulevard du montparnasse\"\n",
    "                }\n",
    "\n",
    "# substitute words\n",
    "not_aligned[\"rue_processed\"] = substitute_col_by_dict(not_aligned[\"rue_processed\"], word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    df_aligned= u_short_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", \n",
    "                    align_method=\"perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    df_aligned= nu_short_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", \n",
    "                    align_method=\"perfect short\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Code to check alignment so far\n",
    "'''\n",
    "# print the most common not aligned streets from the bottin data and possible counterparts in the street network data\n",
    "most_common = Counter(not_aligned[\"rue_processed\"]).most_common(100)\n",
    "for t in most_common:\n",
    "    rue, occur = t\n",
    "    last = rue.split()[-1]\n",
    "    print(rue, occur, [x for x in streets[\"streetname_prep\"] if last in x], \"\\n\")\n",
    "\n",
    "# code to check if something exists in the streets dataset\n",
    "print([x for x in streets[\"streetname_prep\"] if \"boulevards\" in x])\n",
    "print(streets[streets[\"name_prep\"]==\"la fayette\"])\n",
    "\n",
    "# get most common streetnames in not aligned data\n",
    "Counter([x for x in not_aligned[\"rue_processed\"] if \".\" in x]).most_common(100)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Alignment without spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns in all datasets where spaces and some special characters are deleted\n",
    "replace_spaces = {\"\\ \":\"\", \"\\|\":\"\", \"\\.\":\"\", \"\\:\":\"\", \"\\'\":\"\"}\n",
    "not_aligned[\"no_spaces\"] = not_aligned[\"rue_processed\"].replace(replace_spaces, regex=True)\n",
    "streets[\"no_spaces_long\"] = streets[\"streetname_prep\"].replace(replace_spaces, regex=True)\n",
    "unique_short_s[\"no_spaces_short\"] = unique_short_s[\"name_prep\"].replace(replace_spaces, regex=True)\n",
    "non_unique_short_s[\"no_spaces_short\"] = non_unique_short_s[\"name_prep\"].replace(replace_spaces, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_aligned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct alignment\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_long\", \n",
    "                    align_method=\"no spaces perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    df_aligned = u_short_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_short\",\n",
    "                    align_method=\"no spaces perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    df_aligned = nu_short_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_short\",\n",
    "                    align_method=\"no spaces perfect short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligned data so far:\", (len(long_aligned)+len(u_short_aligned)+len(nu_short_aligned))/len(bottins))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of all non aligned street names and a subset for first overview\n",
    "not_aligned_rues = not_aligned[\"rue_processed\"].unique().tolist()\n",
    "not_aligned_selected100 = not_aligned_rues[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all streets from the street network data in one list\n",
    "streets_all_vars = streets[\"streetname_prep\"]\n",
    "streets_all_vars = list(set(streets_all_vars))\n",
    "streets_all_vars[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for different cutoff scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying a fuzzy matching for similarity value 85%\n",
    "for x in not_aligned_selected100:\n",
    "    best_one = process.extractOne(x, streets_all_vars, processor=simple_processor, scorer=fuzz.ratio,\n",
    "    score_cutoff=85)\n",
    "    #if there is a matching street with similarity > 85 %, print it\n",
    "    if best_one:\n",
    "        print(x, best_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying matching with similarity value of 80%\n",
    "for x in not_aligned_selected100:\n",
    "    best_one = process.extractOne(x, streets_all_vars, processor=simple_processor, scorer=fuzz.ratio,\n",
    "    score_cutoff=80)\n",
    "    # look at those matches between 80 and 90%\n",
    "    if best_one:\n",
    "        if best_one[1]<90:\n",
    "            print(x, best_one)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of fuzzy dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make two seperate dictionaries, one with score cutoff value 85 and one with 80\n",
    "#code takes around 3 hours; if this is too long, make a selection like\n",
    "#not_aligned_selected = [street for street, _ in Counter(not_aligned[\"rue_processed\"].tolist()).most_common(10000)]\n",
    "#this still yields good results (1-2% less data aligned)\n",
    "\n",
    "# if dictionary with cutoff 85 is already there, load it. If not, compute it\n",
    "# dictionary of the form {bottin street: most similar street in street data}\n",
    "try:\n",
    "    with open('data/fuzzy_dictwith85.pkl', 'rb') as f:\n",
    "        fuzzy_dict85 = pickle.load(f)\n",
    "except:\n",
    "    fuzzy_dict85 = get_fuzzy_dict(streets_all_vars, not_aligned_rues, score_cutoff=85)\n",
    "    with open(\"data/fuzzy_dictwith85.pkl\",\"wb\") as f:\n",
    "        pickle.dump(fuzzy_dict85,f)\n",
    "\n",
    "# same for dictionary with cutoff 80\n",
    "try:\n",
    "    with open('data/fuzzy_dictwith80.pkl', 'rb') as f:\n",
    "        fuzzy_dict80 = pickle.load(f)\n",
    "except:\n",
    "    fuzzy_dict80 = get_fuzzy_dict(streets_all_vars, not_aligned_rues, score_cutoff=80)\n",
    "    with open(\"data/fuzzy_dictwith80.pkl\",\"wb\") as f:\n",
    "        pickle.dump(fuzzy_dict80,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entries per dictionary\n",
    "print(\"# entries for cutoff 80:\", len(fuzzy_dict80), \"cutoff 85:\", len(fuzzy_dict85))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in not_aligned dataset and map the fuzzy matched streetnames to the entries\n",
    "not_aligned[\"street_fuzzy80\"] = not_aligned[\"rue_processed\"].map(fuzzy_dict80)\n",
    "not_aligned[\"street_fuzzy85\"] = not_aligned[\"rue_processed\"].map(fuzzy_dict85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align on the newly created columns\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"street_fuzzy85\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"fuzzy 85\")\n",
    "\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"street_fuzzy80\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"fuzzy 80\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aligned = pd.concat([long_aligned, u_short_aligned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TAGGED_DATASET:\n",
    "        unique_aligned_selection = unique_aligned[[\"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\", \"tags\"]]\n",
    "        unique_aligned_selection.to_pickle(\"data/unique_aligned_tagged.pkl\")\n",
    "else:\n",
    "        unique_aligned_selection = unique_aligned[[\"page\", \"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\"]]\n",
    "        unique_aligned_selection.to_pickle(\"data/unique_aligned.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of the Alignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aligned = pd.concat([long_aligned, u_short_aligned, nu_short_aligned])\n",
    "all_aligned = all_aligned[[\"page\", \"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\"]]\n",
    "all_streets = pd.concat([streets, unique_short_s, non_unique_short_s])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio of overall aligned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligned data:\", (len(all_aligned))/len(bottins))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview over alignment per method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"perfect\", \"perfect short\", \"no spaces perfect\", \"no spaces perfect short\", \"fuzzy 85\", \"fuzzy 80\"]\n",
    "dev_aligned = {}\n",
    "for method in methods:\n",
    "    dev_aligned[method] = len(all_aligned[all_aligned[\"align_method\"]==method])\n",
    "    print(f\"{round(100*dev_aligned[method]/len(all_aligned), 2)}% of aligned data was aligned by method: {method},\\\n",
    "    ({round(100*dev_aligned[method]/len(bottins), 2)}% of all data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting result\n",
    "plt.bar(dev_aligned.keys(), dev_aligned.values())\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Number of alignment entries per method\\n(alignment in order from left to right)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Assessment of Alignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect Alignment\n",
    "Checking the code below, the alignment is correct in **100%** of the cases.\n",
    "\n",
    "However, the alignment on the short streetnames is by nature sometimes ambiguous, because the short name was used in the Bottin Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"perfect\", \"perfect short\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment without spaces\n",
    "The alignment of the samples below is correct in **100%** of the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"no spaces perfect\", \"no spaces perfect short\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy alignment\n",
    "#### Alignment with threshold 85 (85% of the two strings matched)\n",
    "\n",
    "Correct: **82%**\n",
    "\n",
    "Unclear if correct: **5%**\n",
    "- 3 (\"place\" matched with \"rue\" -> no place in data),\n",
    "- 8 (\"payée\" matched with \"place\" -> no payée in data),\n",
    "- 65 (\"moreau\" matched with \"rue\" -> no moreau in data), \n",
    "- 88 (\"caron\" matched with \"rue\" -> no caron in data),\n",
    "- 92 (\"route\"(ronte) matched with \"rue\" -> no route in data)\n",
    "\n",
    "\n",
    "Incorrect matches: **13%**\n",
    "- 2, 5, 7, 18, 20, 21, 34, 39, 41, 49, 82, 85, 100\n",
    "\n",
    "(many of incorrect matches because there was not the correct streettype (e.g. \"avenue\" instead of \"rue\") and thus matched to different street entirely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"fuzzy 85\"], 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alignment of threshold between 80 and 85\n",
    "\n",
    "correct: **49%**\n",
    "\n",
    "incorrect: **30%**\n",
    "- 3, 4, 6, 9, 13, 15, 23, 28, 31, 38, 39, 40, 41, 43, 44, 45, 47, 49, 53, 55, 56, 58, 65, 67, 78, 79, 85, 86, 94, 95\n",
    "- from this incorrect street type: **3%** (4, 6, 13)\n",
    "\n",
    "unclear: **21%**\n",
    "- 1 (\"rue\" instead of \"quai\")\n",
    "- 8 (\"impasse\" instaed of \"marais\")\n",
    "- 10 (\"rue\" instead of \"place\")\n",
    "- 11 (\"cité\" instead of \"rue\")\n",
    "- 16 (\"impasse\" instead of \"marais\")\n",
    "- 17 (\"rue\" instead of \"cloitre\")\n",
    "- 19 (\"cité\" instead of \"rue\")\n",
    "- 24\n",
    "- 27 (\"rue\" instead of \"pavée\")\n",
    "- 32 (\"cité\" instead of \"rue\")\n",
    "- 33 (\"place\" instead of \"rue\")\n",
    "- 52 (\"rue\" instead of \"passage\")\n",
    "- 59 (\"rue\" instead of \"quai\")\n",
    "- 60 (\"place\" instead of \"rue\")\n",
    "- 69 (\"cité\" instead of \"poteau\")\n",
    "- 70 (\"place\" instead of \"rue\")\n",
    "- 72 (\"rue\" instead of \"square\")\n",
    "- 80 (\"cité\" instead of \"place\")\n",
    "- 82 (\"villa\" instead of \"place\")\n",
    "- 83 (\"cité\" instead of \"rue\")\n",
    "- 99 (\"boulevard\" instead of \"boucherie\")\n",
    "\n",
    "-> many wrongly matched because \"correct\" street (type) was not in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample(all_aligned, [\"fuzzy 80\"], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper code: check for names in street dataset\n",
    "#print([x for x in streets[\"streetname_prep\"] if \"invalides\" in x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting quality of alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a dataframe with absolute numbers of alignment per method and the ratios of the quality\n",
    "alignment_ratios = [1, 1, 1, 1, 0.82, 0.49]\n",
    "df_aligned = {}\n",
    "i=0\n",
    "for key, value in dev_aligned.items():\n",
    "    df_aligned[key] = [value, alignment_ratios[i]]\n",
    "    i+=1\n",
    "statistics = pd.DataFrame.from_dict(df_aligned)\n",
    "\n",
    "# plotting\n",
    "statistics.iloc[0].plot(kind='bar')\n",
    "statistics.iloc[1].plot(secondary_y=True, ylim=(0,1.02), rot=90, color=\"red\")\n",
    "plt.title(\"Number of alignment entries (bars)\\nand quality of alignment (line) per method\\n[alignment in order from left to right]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Aligned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(not_aligned[\"rue\"]).most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of data which rests to be aligned\n",
    "len(not_aligned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct  7 2022, 20:14:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c2682987f00c8c803475925d827e887daeba32793bd1ae3ff6e12f2969d73b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
