{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment\n",
    "## Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from alignment import align_on_column, get_fuzzy_dict\n",
    "from preprocessing import substitute_col_by_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variable to True if you want to use dataset with profession tags (preprocessed with parts of Ravis Code)\n",
    "USE_TAGGED_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TAGGED_DATASET:\n",
    "    bottins = pd.read_pickle(\"data/bottins_tagged_prep.pkl\")\n",
    "else:\n",
    "    bottins = pd.read_pickle(\"data/bottins_prep.pkl\")\n",
    "    \n",
    "streets = pd.read_pickle(\"data/FinalUnique.pkl\")\n",
    "unique_short_s = pd.read_pickle(\"data/unique_short_streets.pkl\")\n",
    "non_unique_short_s = pd.read_pickle(\"data/not_unique_short_streets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottins.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned, not_aligned = align_on_column(df_not_aligned = bottins, df_streets = streets, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"streetname_prep\", align_method=\"perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", align_method=\"perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", align_method=\"perfect short\")                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitute words by dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {\"boulevard\": \"boulevard de\",\n",
    "                \"boulevard de de \": \"boulevard de \",\n",
    "                \"boulevard de d'\": \"boulevard d'\",\n",
    "                \"boulevards\": \"boulevard des\",\n",
    "                \"damede\": \"dame de\",\n",
    "                \"damedes\": \"dame des\",\n",
    "                \"faubourgsaint\": \"faubourg saint\",\n",
    "                \"faubourgpoissonniere\": \"faubourg poissonniere\",\n",
    "                \"faubourgdu\": \"faubourg du\",\n",
    "                \"faubourgmontmartre\": \"faubourg montmartre\",\n",
    "                \"quai jemmapes\": \"quai de jemmapes\",\n",
    "                \"boulevards italiens\": \"boulevard des italiens\",\n",
    "                \"villeneuve\": \"ville neuve\",\n",
    "                \"quai valmy\": \"quai de valmy\",\n",
    "                \"avenue wagram\": \"avenue de wagram\",\n",
    "                \"boulevard de montparnasse\": \"boulevard du montparnasse\"\n",
    "                }\n",
    "\n",
    "# substitute abbreviations\n",
    "not_aligned[\"rue_processed\"] = substitute_col_by_dict(not_aligned[\"rue_processed\"], word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    df_aligned= u_short_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", \n",
    "                    align_method=\"perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    df_aligned= nu_short_aligned, mergeOnLeft=\"rue_processed\", mergeOnRight=\"name_prep\", \n",
    "                    align_method=\"perfect short\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = Counter(not_aligned[\"rue_processed\"]).most_common(100)\n",
    "for t in most_common:\n",
    "    rue, occur = t\n",
    "    last = rue.split()[-1]\n",
    "    print(rue, occur, [x for x in streets[\"streetname_prep\"] if last in x], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if something exists in the streets dataset\n",
    "print([x for x in streets[\"streetname_prep\"] if \"boulevards\" in x])\n",
    "print(streets[streets[\"name_prep\"]==\"la fayette\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common in not aligned data\n",
    "Counter([x for x in not_aligned[\"rue_processed\"] if \".\" in x]).most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment without spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_spaces = {\"\\ \":\"\", \"\\|\":\"\", \"\\.\":\"\", \"\\:\":\"\", \"\\'\":\"\"}\n",
    "not_aligned[\"no_spaces\"] = not_aligned[\"rue_processed\"].replace(replace_spaces, regex=True)\n",
    "streets[\"no_spaces_long\"] = streets[\"streetname_prep\"].replace(replace_spaces, regex=True)\n",
    "unique_short_s[\"no_spaces_short\"] = unique_short_s[\"name_prep\"].replace(replace_spaces, regex=True)\n",
    "non_unique_short_s[\"no_spaces_short\"] = non_unique_short_s[\"name_prep\"].replace(replace_spaces, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_aligned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_long\", \n",
    "                    align_method=\"no spaces perfect\")\n",
    "u_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= unique_short_s, \n",
    "                    df_aligned = u_short_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_short\",\n",
    "                    align_method=\"no spaces perfect short\")\n",
    "nu_short_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= non_unique_short_s, \n",
    "                    df_aligned = nu_short_aligned, mergeOnLeft=\"no_spaces\", mergeOnRight=\"no_spaces_short\",\n",
    "                    align_method=\"no spaces perfect short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_short_aligned.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligned data so far:\", (len(long_aligned)+len(u_short_aligned)+len(nu_short_aligned))/len(bottins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned[[\"nom\", \"metier\", \"rue\", \"numero\", \"year\", \"streetname\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_aligned[[\"nom\", \"metier\", \"rue\", \"numero\", \"year\", \"streetname\", \"no_spaces\"]].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_unique_short_s[[\"name_prep\", \"streetname\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in not_aligned[\"rue\"] if (\"5\" in x)][10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "def simple_processor(token: str) -> str:\n",
    "    \"\"\"A string processor to return the same string as input.\n",
    "        This dummy processor is used to avoid the default processor of the Rapidfuzz module to calculate string similarity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token : str\n",
    "        The input string to process.\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The output string same as the input string.\n",
    "    \"\"\"\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a subset of all non-aligned rows, because otherwise computation is too heavy\n",
    "not_aligned_rues = not_aligned[\"rue_processed\"].unique().tolist()\n",
    "not_aligned_selected = [street for street, _ in Counter(not_aligned[\"rue_processed\"].tolist()).most_common(10000)]\n",
    "#first 100 streets for first analysis\n",
    "not_aligned_selected100 = not_aligned_rues[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_all_vars = streets[\"streetname_prep\"]\n",
    "#streets_all_vars.append(streets[\"streetname_short\"])\n",
    "#streets_all_vars.append(streets[\"streetname_short_prep\"])\n",
    "streets_all_vars = list(set(streets_all_vars))\n",
    "streets_all_vars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying a fuzzy matching for similarity value 85%\n",
    "for x in not_aligned_selected100:\n",
    "    best_one = process.extractOne(x, streets_all_vars, processor=simple_processor, scorer=fuzz.ratio,\n",
    "    score_cutoff=85)\n",
    "    #if there is a matching street with similarity > 85 %, print it\n",
    "    if best_one:\n",
    "        print(x, best_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying matching with similarity value of 80%\n",
    "for x in not_aligned_selected100:\n",
    "    best_one = process.extractOne(x, streets_all_vars, processor=simple_processor, scorer=fuzz.ratio,\n",
    "    score_cutoff=80)\n",
    "    # look at those matches between 80 and 90%\n",
    "    if best_one:\n",
    "        if best_one[1]<90:\n",
    "            print(x, best_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fuzzy_dict(streets_all_vars, not_aligned_selected100, score_cutoff=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make two seperate dictionaries, one with score cutoff value 85 and one with 80\n",
    "\n",
    "# if dictionary with cutoff 85 is already there, load it. If not, compute it\n",
    "try:\n",
    "    with open('data/fuzzy_dict10000with85.pkl', 'rb') as f:\n",
    "        fuzzy_dict85 = pickle.load(f)\n",
    "except:\n",
    "    fuzzy_dict85 = get_fuzzy_dict(streets_all_vars, not_aligned_selected, score_cutoff=85)\n",
    "    with open(\"data/fuzzy_dict10000with85.pkl\",\"wb\") as f:\n",
    "        pickle.dump(fuzzy_dict85,f)\n",
    "\n",
    "# same for dictionary with cutoff 80\n",
    "try:\n",
    "    with open('data/fuzzy_dict10000with80.pkl', 'rb') as f:\n",
    "        fuzzy_dict80 = pickle.load(f)\n",
    "except:\n",
    "    fuzzy_dict80 = get_fuzzy_dict(streets_all_vars, not_aligned_selected, score_cutoff=80)\n",
    "    with open(\"data/fuzzy_dict10000with80.pkl\",\"wb\") as f:\n",
    "        pickle.dump(fuzzy_dict80,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# entries for cutoff 80:\", len(fuzzy_dict80), \"cutoff 85:\", len(fuzzy_dict85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in fuzzy_dict85.items():\n",
    "    if \".\" in item[0]:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in not_aligned dataset and map the fuzzy matched streetnames to the entries\n",
    "not_aligned[\"street_fuzzy80\"] = not_aligned[\"rue_processed\"].map(fuzzy_dict80)\n",
    "not_aligned[\"street_fuzzy85\"] = not_aligned[\"rue_processed\"].map(fuzzy_dict85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align on the newly created columns\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"street_fuzzy85\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"fuzzy 85\")\n",
    "\n",
    "long_aligned, not_aligned = align_on_column(df_not_aligned = not_aligned, df_streets= streets, \n",
    "                    df_aligned = long_aligned, mergeOnLeft=\"street_fuzzy80\", mergeOnRight=\"streetname_prep\", \n",
    "                    align_method=\"fuzzy 80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligned data:\", (len(long_aligned)+len(u_short_aligned)+len(nu_short_aligned))/len(bottins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aligned = pd.concat([long_aligned, u_short_aligned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TAGGED_DATASET:\n",
    "        unique_aligned_selection = unique_aligned[[\"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\", \"tags\"]]\n",
    "        unique_aligned_selection.to_pickle(\"data/unique_aligned_tagged.pkl\")\n",
    "else:\n",
    "        unique_aligned_selection = unique_aligned[[\"page\", \"row\", \"nom\", \"metier\", \"rue\", \"numero\", \n",
    "                \"annee\", \"streetname\", \"geometry\", \"name\", \"year\", \"align_method\"]]\n",
    "        unique_aligned_selection.to_pickle(\"data/unique_aligned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aligned_selection.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aligned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "098a0dd3104dda9245e32bc4140980e8acec008f0fd7b1a1afbd38055ea17b26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
